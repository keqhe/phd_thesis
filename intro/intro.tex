\chapter{Introduction}
\label{thesis:chapter:intro}

Cloud computing is changing the way computing is conducted since a few years ago.
It is a rapidly growing business and many industry leaders
(\eg{}, Amazon~\cite{amazon-aws}, Google~\cite{google-compute}, 
IBM~\cite{ibm-softlayer,ibm-bluemix} and
Microsoft~\cite{microsoft-azure}) have embraced such a
business model and are deploying highly advanced cloud computing infrastructures.
Market analysis~\cite{cloud-market2020}
has predicted that the global cloud computing market will
reach \$270 billion by 2020. The success of cloud computing is
not accidental \textemdash\xspace it is rooted in many advantages that cloud computing offers
over traditional computing model. The most notable feature is that tenants
(customers) who rent the computing resources can get equivalent computing power
with \emph{lower cost}. That is because the computing resources
(CPUs, memory, storage, and network) are shared among multiple users and
server consolidation and server virtualization improve the utilization
of the computing resources. Another key advantage cloud computing offers
is \emph{computing agility}. That means, tenants can rent as many computing
resources as they need and can grow or shrink the computing pool based on their demands.
This feature is especially attractive for relatively smaller and
rapidly growing businesses.

Datacenter networks are important components in modern cloud computing infrastructures. 
High-performance cloud computing infrastructures require high-speed, low latency, scalable and 
highly robust datacenter networking solutions to support a massive amount of traffic. 
For example, Cisco Global Cloud Index~\cite{cisco-predict} predicts that annual global datacenter IP traffic will 
reach 15.3 zettabytes (ZB) by 2020, which is 3 times large as 2015's (4.7 ZB). 
The tremendous growth of datacenter traffic drives the need for high-performance 
datacenter networking solutions. Datacenter network is a complicated system and it covers many 
aspects of computer networking, ranging from TCP congestion control algorithms to switch hardware design. 
In the past 10 years, datacenter networking technologies have been advanced significantly. 
Starting in 2009 - 2010, seminal works on datacenter network topology designs such as 
FatTree~\cite{fattree} and VL2~\cite{vl2} were published. These works proposed to use multi-stage Clos networks to 
scale out and support hundreds of thousands of servers in a single datacenter. 
Recently (in 2016), Microsoft published their congestion control solution for 
RDMA deployments in Azure networks~\cite{zhu2015congestion}. 
Despite the advances, there are still a lot of unsolved research challenges in datacenter networking.

In 2007, Casado et al~\cite{casado2007ethane} presented a control plane and dataplane separation network architecture for 
Enterprise networks. In 2008, networking researchers, McKeown et al, argued that today's computer network 
devices (i.e., switch and routers) were commercialized black boxes, 
and it was increasingly harder for networking researchers to invent and test new networking 
techniques on existing networking devices. Their white paper~\cite{McKeown08} described the initial motivation 
for OpenFlow. Ethane and OpenFlow started the revolution of Software-defined Networking (SDN). 
Later, an open source implementation of SDN-capable virtual switch, Open vSwitch (OVS)~\cite{Pfaff2015ovs}, was released. 
OVS is now maintained by VMware. Datacenter networking and SDN technique are closely related. 
In datacenter networks, SDN technique is widely applied. Of particular importance, 
OVS is widely deployed in cloud computing platforms to support network virtualization functionalities and 
meet SDN-style network management requirements. OVS is one part of end-host networking.
End-host networking covers many components, for example, TCP/IP stack, virtual switch, rate limiters and NIC hardware. 
In a datacenter network, all the servers (and hypervisors) are managed by a single entity 
(i.e., the cloud provider), therefore, there are a lof of opportunities for innovations.

In this thesis, I will present my research works on improving datacenter networking performance. 
Performance here refers to network throughput, latency and packet loss etc. 
The major theme of this thesis is to leverage the intelligent software-defined network 
edge (i.e., end-host networking) to improve performance for datacenter networks.
In the following of this chapter, I will briefly introduce three research projects I worked on 
during my PhD study, they are \textemdash\xspace edge-based traffic load balancing for 
datacenter networks, congestion control virtualization for multi-tenant clouds and 
low latency software rate limiters for cloud networks.

\section{Edge-based traffic load balancing}
% virtual network data plane

%While our work applies to general cloud networking settings, for the purposes of 
In this thesis, we focus on multi-tenant cloud data centers.
In this setting, tenants deploy \emph{virtual private clusters}
composed of application end-points (this could be service software in

\section{Congestion control virtualization}
\section{Low latency software rate limiters}



\section{Summary of Contributions and Overview}
\label{sec:intro:challenges}
Troubleshooting network problems is difficult. A network is a distributed

\begin{itemize}
\item Cloud networks have higher complexity than traditional networks.  In data planes, network virtualization introduces more software components, including software switches, hypervisors, and so on; software middleboxes are introduced to support network function virtualization. In control planes, the cloud controllers need to perform more functions to set up virtual networks; the controllers map tenants' requirements from a logical view to a physical view, and finally to devices rules. Cloud networks involve a greater number of components involved, and these components may have logical or physical dependency (e.g., exchanging data or sharing hardware resources). This complexity in cloud networks makes them not only more error-prone but also difficulty to manage and diagnose.
\item The two roles in cloud networks makes the management trickier than traditional network. The two roles are the provider (or operator) and the tenants, and their information is isolated from each
other. In the case of network problems, the interaction between the provider and
the tenants is crucial for problem solving; however, this process is usually of low efficiency. 
The tenants observe misbehaviors of their applications directly, but they lack diagnostic tools.
The provider does not know the applications' performance, so they can only wait for tenants' tickets.
%Due to the isolation, both parties cannot perform a complete diagnosis; therefore, 
The two parties need to exchange observations to figure out the problem. This manual process increases
the problem-solving time and maintenance cost.
\item The visibility of cloud networks is not well provided to customers and operators. In traditional networks, network devices and components provide various information for operators to monitor or troubleshoot, e.g., packet drop statistics in switches and the network protocol stack. However, by our study, this kind of visibility is not well preserved in cloud networks. For customers, the cloud provider does not provide visibility of how their packets traverse the network for security reasons. For the provider, some virtualization components are introduced to cloud networks without keeping the visibility for diagnosis\textemdash there are several silent packet drops in VM hypervisors and software middleboxes. This is partially due to the fact that developers typically focus on functionality instead of diagnostic features in the first few versions of the software.
\end{itemize}


